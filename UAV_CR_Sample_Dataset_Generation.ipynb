{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJomgHzvqO91AJEqhZs2OY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiwkumar/UAV_CR/blob/main/UAV_CR_Sample_Dataset_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCncZNSTCcfA",
        "outputId": "eee31d07-742b-49bd-8965-2c1f41bf498a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy scipy h5py tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define parameters\n",
        "signal_params = {\n",
        "    'center_frequency': 2.4e9,  # Hz (2.4 GHz ISM band)\n",
        "    'bandwidth': 20e6,         # Hz (20 MHz channels)\n",
        "    'sampling_rate': 40e6,     # Hz (2x Nyquist rate)\n",
        "    'duration': 1e-3,          # seconds per sample\n",
        "    'snr_range': [-20, 5],     # dB\n",
        "    'modulation_types': ['BPSK', 'QPSK', '16-QAM', '64-QAM']\n",
        "}\n",
        "\n",
        "uav_params = {\n",
        "    'altitude_range': [50, 200],    # meters\n",
        "    'velocity_range': [0, 15],      # m/s\n",
        "    'number_of_uavs': [2, 4, 6, 8], # Different scenarios\n",
        "}\n",
        "\n",
        "channel_params = {\n",
        "    'path_loss_exponent': 2.7,      # Urban environment\n",
        "    'shadowing_std': 4.0,           # dB\n",
        "    'fading_type': 'Rician',        # For LOS scenarios\n",
        "    'K_factor': 10,                 # Rician K-factor\n",
        "    'doppler_shift': True,          # Consider UAV mobility\n",
        "}\n",
        "\n",
        "training_data = {\n",
        "    'size': 10000,            # Number of samples\n",
        "    'distribution': {\n",
        "        'training': 0.7,       # 70% for training\n",
        "        'validation': 0.15,    # 15% for validation\n",
        "        'testing': 0.15        # 15% for testing\n",
        "    }\n",
        "}\n",
        "\n",
        "def generate_dataset():\n",
        "    \"\"\"Generate synthetic dataset for CR-UAV testing\"\"\"\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for i in tqdm(range(training_data['size']), desc=\"Generating samples\"):\n",
        "        # Generate UAV position\n",
        "        x = np.random.uniform(-100, 100)\n",
        "        y = np.random.uniform(-100, 100)\n",
        "        z = np.random.uniform(*uav_params['altitude_range'])\n",
        "        position = (x, y, z)\n",
        "\n",
        "        # Generate UAV velocity\n",
        "        vx = np.random.uniform(-uav_params['velocity_range'][1], uav_params['velocity_range'][1])\n",
        "        vy = np.random.uniform(-uav_params['velocity_range'][1], uav_params['velocity_range'][1])\n",
        "        vz = np.random.uniform(-5, 5)  # Smaller vertical velocity range\n",
        "        velocity = (vx, vy, vz)\n",
        "\n",
        "        # Generate SNR\n",
        "        snr = np.random.uniform(*signal_params['snr_range'])\n",
        "\n",
        "        # Calculate signal power based on path loss and shadowing\n",
        "        distance = np.sqrt(x**2 + y**2 + z**2)\n",
        "        path_loss = 20 * np.log10(distance) + 20 * np.log10(signal_params['center_frequency']) - 147.55\n",
        "        shadowing = np.random.normal(0, channel_params['shadowing_std'])\n",
        "\n",
        "        # Calculate received power\n",
        "        tx_power = 23  # dBm (typical WiFi transmit power)\n",
        "        rx_power = tx_power - path_loss + shadowing\n",
        "\n",
        "        # Generate channel conditions\n",
        "        K = channel_params['K_factor']\n",
        "        fading = np.sqrt(K/(K+1)) + np.sqrt(1/(K+1)) * (np.random.normal(0,1) + 1j*np.random.normal(0,1))\n",
        "        fading_magnitude = np.abs(fading)\n",
        "\n",
        "        # Generate spectrum occupancy (primary user presence)\n",
        "        primary_user_present = 1 if np.random.random() > 0.5 else 0\n",
        "\n",
        "        # Select modulation type\n",
        "        modulation = np.random.choice(signal_params['modulation_types'])\n",
        "\n",
        "        # Store sample\n",
        "        sample = {\n",
        "            'x': x,\n",
        "            'y': y,\n",
        "            'z': z,\n",
        "            'vx': vx,\n",
        "            'vy': vy,\n",
        "            'vz': vz,\n",
        "            'snr': snr,\n",
        "            'path_loss': path_loss,\n",
        "            'shadowing': shadowing,\n",
        "            'rx_power': rx_power,\n",
        "            'fading_magnitude': fading_magnitude,\n",
        "            'primary_user_present': primary_user_present,\n",
        "            'modulation': modulation\n",
        "        }\n",
        "\n",
        "        dataset.append(sample)\n",
        "\n",
        "    return pd.DataFrame(dataset)\n",
        "\n",
        "# Generate dataset\n",
        "df = generate_dataset()\n",
        "\n",
        "# Save to HDF5 file\n",
        "df.to_hdf('cr_uav_dataset_10k.h5', key='data', mode='w')\n",
        "\n",
        "# Print dataset statistics\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(\"-------------------\")\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Primary user presence ratio: {df['primary_user_present'].mean():.2f}\")\n",
        "print(\"\\nNumerical Features Statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\nModulation Distribution:\")\n",
        "print(df['modulation'].value_counts(normalize=True))\n",
        "\n",
        "# Create visualization of key parameters\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# SNR Distribution\n",
        "sns.histplot(data=df, x='snr', bins=30, ax=axes[0,0])\n",
        "axes[0,0].set_title('SNR Distribution')\n",
        "\n",
        "# Path Loss vs Distance\n",
        "distance = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
        "axes[0,1].scatter(distance, df['path_loss'], alpha=0.1)\n",
        "axes[0,1].set_title('Path Loss vs Distance')\n",
        "axes[0,1].set_xlabel('Distance (m)')\n",
        "axes[0,1].set_ylabel('Path Loss (dB)')\n",
        "\n",
        "# Received Power Distribution\n",
        "sns.histplot(data=df, x='rx_power', bins=30, ax=axes[1,0])\n",
        "axes[1,0].set_title('Received Power Distribution')\n",
        "\n",
        "# UAV Altitude Distribution\n",
        "sns.histplot(data=df, x='z', bins=30, ax=axes[1,1])\n",
        "axes[1,1].set_title('UAV Altitude Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('dataset_visualization.png')\n",
        "plt.close()\n",
        "\n",
        "# Save dataset split indices\n",
        "n_samples = len(df)\n",
        "indices = np.random.permutation(n_samples)\n",
        "train_size = int(n_samples * training_data['distribution']['training'])\n",
        "val_size = int(n_samples * training_data['distribution']['validation'])\n",
        "\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size:train_size+val_size]\n",
        "test_indices = indices[train_size+val_size:]\n",
        "\n",
        "np.savez('dataset_splits.npz',\n",
        "         train_indices=train_indices,\n",
        "         val_indices=val_indices,\n",
        "         test_indices=test_indices)\n",
        "\n",
        "print(\"\\nDataset Split Information:\")\n",
        "print(f\"Training samples: {len(train_indices)}\")\n",
        "print(f\"Validation samples: {len(val_indices)}\")\n",
        "print(f\"Testing samples: {len(test_indices)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD5qAryHCjAN",
        "outputId": "243e530b-26d3-4d4e-a951-672d6c993fa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating samples: 100%|██████████| 10000/10000 [00:00<00:00, 10210.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Statistics:\n",
            "-------------------\n",
            "Total samples: 10000\n",
            "Primary user presence ratio: 0.49\n",
            "\n",
            "Numerical Features Statistics:\n",
            "                  x             y             z            vx            vy  \\\n",
            "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
            "mean      -0.204654      0.619572    125.446803     -0.074512     -0.025586   \n",
            "std       57.639156     57.378128     42.884137      8.732563      8.661804   \n",
            "min      -99.990328    -99.984903     50.004507    -14.999576    -14.998112   \n",
            "25%      -50.216813    -49.583661     88.544538     -7.736886     -7.495069   \n",
            "50%        0.717120      0.996584    125.880652     -0.112508     -0.150204   \n",
            "75%       49.356557     50.159262    162.190944      7.529662      7.564317   \n",
            "max       99.986033     99.976639    199.998335     14.997358     14.998199   \n",
            "\n",
            "                 vz           snr     path_loss     shadowing      rx_power  \\\n",
            "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
            "mean      -0.045655     -7.470074     83.298892     -0.071286    -60.370178   \n",
            "std        2.892605      7.229416      2.406508      3.989477      4.637984   \n",
            "min       -4.999446    -19.999791     74.302194    -16.306590    -77.302622   \n",
            "25%       -2.560156    -13.638764     81.691419     -2.739131    -63.476232   \n",
            "50%       -0.072283     -7.545567     83.615197     -0.056140    -60.416936   \n",
            "75%        2.420913     -1.074254     85.250798      2.623335    -57.295939   \n",
            "max        4.999856      4.999825     87.803435     14.333835    -42.890184   \n",
            "\n",
            "       fading_magnitude  primary_user_present  \n",
            "count      10000.000000          10000.000000  \n",
            "mean           1.003101              0.492700  \n",
            "std            0.296624              0.499972  \n",
            "min            0.006493              0.000000  \n",
            "25%            0.799751              0.000000  \n",
            "50%            1.002079              0.000000  \n",
            "75%            1.204500              1.000000  \n",
            "max            2.196201              1.000000  \n",
            "\n",
            "Modulation Distribution:\n",
            "modulation\n",
            "BPSK      0.2558\n",
            "16-QAM    0.2529\n",
            "QPSK      0.2495\n",
            "64-QAM    0.2418\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Dataset Split Information:\n",
            "Training samples: 7000\n",
            "Validation samples: 1500\n",
            "Testing samples: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd1\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "\n",
        "class StackelbergGame:\n",
        "    def __init__(self, num_secondary_users=4):\n",
        "        self.num_su = num_secondary_users\n",
        "        self.sensing_time = 0.001  # 1ms sensing time\n",
        "        self.sampling_rate = 40e6  # 40MHz sampling rate\n",
        "        self.samples_per_sensing = int(self.sensing_time * self.sampling_rate)\n",
        "        self.noise_variance = 1.0\n",
        "        self.price_coefficient = 0.1\n",
        "        self.energy_coefficient = 0.01\n",
        "\n",
        "    def leader_utility(self, price, detection_prob):\n",
        "        \"\"\"Primary user (leader) utility function\"\"\"\n",
        "        return price * detection_prob - self.price_coefficient * price**2\n",
        "\n",
        "    def follower_utility(self, detection_prob, sensing_time, price):\n",
        "        \"\"\"Secondary user (follower) utility function\"\"\"\n",
        "        energy_cost = self.energy_coefficient * sensing_time\n",
        "        return detection_prob - price * sensing_time - energy_cost\n",
        "\n",
        "    def calculate_detection_probability(self, snr, sensing_time):\n",
        "        \"\"\"Calculate probability of detection using SNR and sensing time\"\"\"\n",
        "        samples = int(sensing_time * self.sampling_rate)\n",
        "        Q = lambda x: 0.5 * (1 - norm.cdf(x/np.sqrt(2)))\n",
        "        pf = 0.1  # Fixed false alarm probability\n",
        "\n",
        "        lambda_thresh = self.noise_variance * (1 + np.sqrt(2/samples) * norm.ppf(1-pf))\n",
        "        gamma = 10**(snr/10)\n",
        "        pd = Q((lambda_thresh/self.noise_variance - gamma - 1) * np.sqrt(samples/2/(2*gamma + 1)))\n",
        "        return pd\n",
        "\n",
        "    def optimize_price(self, snr):\n",
        "        \"\"\"Optimize price for primary user\"\"\"\n",
        "        prices = np.linspace(0.1, 2, 100)\n",
        "        max_utility = -np.inf\n",
        "        optimal_price = prices[0]\n",
        "\n",
        "        for price in prices:\n",
        "            sensing_time = self.optimize_sensing_time(price, snr)\n",
        "            pd = self.calculate_detection_probability(snr, sensing_time)\n",
        "            utility = self.leader_utility(price, pd)\n",
        "\n",
        "            if utility > max_utility:\n",
        "                max_utility = utility\n",
        "                optimal_price = price\n",
        "\n",
        "        return optimal_price\n",
        "\n",
        "    def optimize_sensing_time(self, price, snr):\n",
        "        \"\"\"Optimize sensing time for secondary users\"\"\"\n",
        "        sensing_times = np.linspace(0.1e-3, 2e-3, 100)\n",
        "        max_utility = -np.inf\n",
        "        optimal_time = sensing_times[0]\n",
        "\n",
        "        for time in sensing_times:\n",
        "            pd = self.calculate_detection_probability(snr, time)\n",
        "            utility = self.follower_utility(pd, time, price)\n",
        "\n",
        "            if utility > max_utility:\n",
        "                max_utility = utility\n",
        "                optimal_time = time\n",
        "\n",
        "        return optimal_time\n",
        "\n",
        "def run_simulation(dataset_path, simulation_time=60):\n",
        "    \"\"\"Run spectrum sensing simulation for 60 seconds\"\"\"\n",
        "    # Load dataset\n",
        "    df = pd1.read_hdf(dataset_path)\n",
        "\n",
        "    # Initialize parameters\n",
        "    game = StackelbergGame(num_secondary_users=4)\n",
        "    sensing_interval = 0.001  # 1ms\n",
        "    num_iterations = int(simulation_time / sensing_interval)\n",
        "    snr_range = np.arange(-20, 6, 1)\n",
        "\n",
        "    # Initialize results storage\n",
        "    detection_probabilities = {snr: [] for snr in snr_range}\n",
        "    price_history = []\n",
        "    sensing_time_history = []\n",
        "\n",
        "    # Run simulation\n",
        "    print(\"\\nRunning Stackelberg Game simulation...\")\n",
        "    for snr in tqdm(snr_range):\n",
        "        # Filter dataset for current SNR\n",
        "        snr_data = df[np.abs(df['snr'] - snr) < 0.5]\n",
        "\n",
        "        if len(snr_data) > 0:\n",
        "            # Optimize price and sensing time\n",
        "            optimal_price = game.optimize_price(snr)\n",
        "            optimal_sensing_time = game.optimize_sensing_time(optimal_price, snr)\n",
        "\n",
        "            # Calculate detection probability\n",
        "            pd = game.calculate_detection_probability(snr, optimal_sensing_time)\n",
        "\n",
        "            detection_probabilities[snr].append(pd)\n",
        "            price_history.append(optimal_price)\n",
        "            sensing_time_history.append(optimal_sensing_time)\n",
        "\n",
        "    # Process results\n",
        "    avg_detection_prob = {snr: np.mean(probs) if probs else 0\n",
        "                         for snr, probs in detection_probabilities.items()}\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Plot detection probability vs SNR\n",
        "    snrs = list(avg_detection_prob.keys())\n",
        "    pds = list(avg_detection_prob.values())\n",
        "\n",
        "    plt.plot(snrs, pds, 'b-', linewidth=2, label='Stackelberg Game')\n",
        "\n",
        "    # Add theoretical curve for comparison\n",
        "    theoretical_pd = [game.calculate_detection_probability(snr, np.mean(sensing_time_history))\n",
        "                     for snr in snrs]\n",
        "    plt.plot(snrs, theoretical_pd, 'r--', linewidth=2, label='Theoretical')\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Probability of Detection')\n",
        "    plt.title('Spectrum Sensing Performance using Stackelberg Game\\n'\n",
        "              f'(Number of SUs: {game.num_su}, Simulation Time: {simulation_time}s)')\n",
        "    plt.legend()\n",
        "    plt.ylim([0, 1])\n",
        "\n",
        "    # Save plot\n",
        "    plt.savefig('stackelberg_simulation_results.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nSimulation Results:\")\n",
        "    print(\"------------------\")\n",
        "    print(f\"Average Detection Probability: {np.mean(list(avg_detection_prob.values())):.4f}\")\n",
        "    print(f\"Average Price: {np.mean(price_history):.4f}\")\n",
        "    print(f\"Average Sensing Time: {np.mean(sensing_time_history)*1000:.2f} ms\")\n",
        "\n",
        "    # Save detailed results\n",
        "    results = {\n",
        "        'snr': snrs,\n",
        "        'detection_probability': pds,\n",
        "        'theoretical_pd': theoretical_pd,\n",
        "        'price_history': price_history,\n",
        "        'sensing_time_history': sensing_time_history\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run simulation\n",
        "    results = run_simulation('cr_uav_dataset_10k.h5')\n",
        "\n",
        "    # Save results to file\n",
        "    np.savez('stackelberg_simulation_results.npz', **results)\n",
        "\n",
        "    # Create additional analysis plots\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Price history\n",
        "    plt.subplot(121)\n",
        "    plt.plot(results['snr'], results['price_history'], 'g-')\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Optimal Price')\n",
        "    plt.title('Price vs SNR')\n",
        "\n",
        "    # Sensing time history\n",
        "    plt.subplot(122)\n",
        "    plt.plot(results['snr'], np.array(results['sensing_time_history'])*1000, 'm-')\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Optimal Sensing Time (ms)')\n",
        "    plt.title('Sensing Time vs SNR')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('stackelberg_additional_analysis.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5v9whFMFLBz",
        "outputId": "58327a1c-b41d-4327-b801-26fcd6c4f02b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Stackelberg Game simulation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [01:25<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulation Results:\n",
            "------------------\n",
            "Average Detection Probability: 0.4878\n",
            "Average Price: 1.9897\n",
            "Average Sensing Time: 0.63 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd3\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "class StackelbergGame:\n",
        "    def __init__(self, num_secondary_users=4):\n",
        "        self.num_sus = num_secondary_users\n",
        "        self.sensing_time = 0.001  # 1ms sensing interval\n",
        "        self.total_time = 60  # 1 minute simulation\n",
        "        self.num_iterations = int(self.total_time / self.sensing_time)\n",
        "\n",
        "        # Game parameters\n",
        "        self.price_coefficient = 0.1\n",
        "        self.cost_coefficient = 0.05\n",
        "        self.interference_threshold = -80  # dBm\n",
        "        self.energy_constraint = 100  # mJ\n",
        "\n",
        "    def utility_primary(self, price, interference, revenue_coefficient=1.0):\n",
        "        \"\"\"Primary user utility function\"\"\"\n",
        "        return revenue_coefficient * price - self.cost_coefficient * interference\n",
        "\n",
        "    def utility_secondary(self, detection_prob, price, energy):\n",
        "        \"\"\"Secondary user utility function\"\"\"\n",
        "        return np.log(1 + detection_prob) - price * energy\n",
        "\n",
        "    def calculate_detection_probability(self, snr, sensing_time, pf=0.1):\n",
        "        \"\"\"Calculate probability of detection using SNR\"\"\"\n",
        "        samples = int(sensing_time * 40e6)  # Using sampling rate from dataset\n",
        "        gamma = 10**(snr/10)\n",
        "        Q_inv = stats.norm.ppf(1-pf)\n",
        "\n",
        "        pd = stats.norm.sf((Q_inv * np.sqrt(2*samples) - gamma * np.sqrt(samples)) /\n",
        "                          np.sqrt(2*samples + 4*gamma*samples))\n",
        "        return pd\n",
        "\n",
        "    def optimize_price(self, snr, interference):\n",
        "        \"\"\"Primary user optimization\"\"\"\n",
        "        prices = np.linspace(0.1, 1.0, 100)\n",
        "        utilities = [self.utility_primary(p, interference) for p in prices]\n",
        "        return prices[np.argmax(utilities)]\n",
        "\n",
        "    def optimize_sensing(self, price, snr, energy_available):\n",
        "        \"\"\"Secondary user optimization\"\"\"\n",
        "        sensing_times = np.linspace(0.1e-3, 1e-3, 100)\n",
        "        utilities = []\n",
        "\n",
        "        for st in sensing_times:\n",
        "            pd = self.calculate_detection_probability(snr, st)\n",
        "            energy = st * energy_available\n",
        "            utility = self.utility_secondary(pd, price, energy)\n",
        "            utilities.append(utility)\n",
        "\n",
        "        return sensing_times[np.argmax(utilities)]\n",
        "\n",
        "def run_simulation():\n",
        "    # Load dataset\n",
        "    df = pd3.read_hdf('cr_uav_dataset_10k.h5', key='data')\n",
        "\n",
        "    # Initialize simulation parameters\n",
        "    game = StackelbergGame(num_secondary_users=4)\n",
        "    snr_range = np.arange(-20, 6, 1)\n",
        "    results = []\n",
        "\n",
        "    # Run simulation for each SNR value\n",
        "    for snr in tqdm(snr_range, desc=\"Simulating SNR ranges\"):\n",
        "        snr_results = []\n",
        "\n",
        "        # Filter dataset for current SNR range\n",
        "        df_snr = df[np.abs(df['snr'] - snr) < 0.5]\n",
        "        if len(df_snr) < game.num_iterations:\n",
        "            df_snr = df_snr.sample(n=game.num_iterations, replace=True)\n",
        "\n",
        "        # Run iterations for current SNR\n",
        "        for i in range(game.num_iterations):\n",
        "            # Get current channel conditions\n",
        "            current_data = df_snr.iloc[i]\n",
        "            interference = current_data['rx_power']\n",
        "            true_presence = current_data['primary_user_present']\n",
        "\n",
        "            # Primary user strategy\n",
        "            optimal_price = game.optimize_price(snr, interference)\n",
        "\n",
        "            # Secondary users strategies\n",
        "            detection_probs = []\n",
        "            for su in range(game.num_sus):\n",
        "                # Each SU has slightly different energy availability\n",
        "                energy_available = game.energy_constraint * (0.8 + 0.4 * np.random.random())\n",
        "                optimal_sensing_time = game.optimize_sensing(optimal_price, snr, energy_available)\n",
        "                pd = game.calculate_detection_probability(snr, optimal_sensing_time)\n",
        "                detection_probs.append(pd)\n",
        "\n",
        "            # Cooperative decision (OR-rule)\n",
        "            final_detection = 1 - np.prod([1-pd for pd in detection_probs])\n",
        "            snr_results.append({\n",
        "                'snr': snr,\n",
        "                'detection_prob': final_detection,\n",
        "                'true_presence': true_presence,\n",
        "                'price': optimal_price,\n",
        "                'avg_sensing_time': np.mean(optimal_sensing_time)\n",
        "            })\n",
        "\n",
        "        results.extend(snr_results)\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate average detection probability for each SNR\n",
        "    snr_performance = results_df.groupby('snr').agg({\n",
        "        'detection_prob': ['mean', 'std'],\n",
        "        'price': 'mean',\n",
        "        'avg_sensing_time': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.errorbar(snr_performance['snr'],\n",
        "                snr_performance['detection_prob']['mean'],\n",
        "                yerr=snr_performance['detection_prob']['std'],\n",
        "                fmt='o-', capsize=5)\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Probability of Detection')\n",
        "    plt.title('Detection Performance vs SNR in UAV Network\\n(Stackelberg Game)')\n",
        "    plt.savefig('stackelberg_simulation_results.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Create detailed performance report\n",
        "    print(\"\\nSimulation Results Summary\")\n",
        "    print(\"--------------------------\")\n",
        "    print(f\"Number of Secondary Users: {game.num_sus}\")\n",
        "    print(f\"Total Simulation Time: {game.total_time} seconds\")\n",
        "    print(f\"Sensing Interval: {game.sensing_time} seconds\")\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(snr_performance.round(4))\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('stackelberg_simulation_results.csv', index=False)\n",
        "\n",
        "    return results_df, snr_performance\n",
        "\n",
        "# Additional visualization for game dynamics\n",
        "def plot_game_dynamics(results_df):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot 1: Price vs SNR\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.boxplot(x='snr', y='price', data=results_df)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Optimal Price')\n",
        "    plt.title('Price Dynamics')\n",
        "\n",
        "    # Plot 2: Sensing Time vs SNR\n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.boxplot(x='snr', y='avg_sensing_time', data=results_df)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Average Sensing Time (s)')\n",
        "    plt.title('Sensing Time Dynamics')\n",
        "\n",
        "    # Plot 3: Detection Probability Distribution\n",
        "    plt.subplot(1, 3, 3)\n",
        "    sns.boxplot(x='snr', y='detection_prob', data=results_df)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Detection Probability')\n",
        "    plt.title('Detection Probability Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('stackelberg_game_dynamics.png')\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run simulation\n",
        "    results_df, snr_performance = run_simulation()\n",
        "\n",
        "    # Plot additional dynamics\n",
        "    plot_game_dynamics(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "z7nmVmPXHG9G",
        "outputId": "e5335a46-bcda-4a42-ac1a-677d0f6cee11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simulating SNR ranges:   0%|          | 0/26 [01:32<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d9bd92d25671>\u001b[0m in \u001b[0;36m<cell line: 173>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# Plot additional dynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d9bd92d25671>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;31m# Each SU has slightly different energy availability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0menergy_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_constraint\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0moptimal_sensing_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_sensing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_available\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_detection_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_sensing_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mdetection_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d9bd92d25671>\u001b[0m in \u001b[0;36moptimize_sensing\u001b[0;34m(self, price, snr, energy_available)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensing_times\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_detection_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menergy_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility_secondary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d9bd92d25671>\u001b[0m in \u001b[0;36mcalculate_detection_probability\u001b[0;34m(self, snr, sensing_time, pf)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mQ_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         pd = stats.norm.sf((Q_inv * np.sqrt(2*samples) - gamma * np.sqrt(samples)) / \n\u001b[0m\u001b[1;32m     36\u001b[0m                           np.sqrt(2*samples + 4*gamma*samples))\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz4XcXXIJTP2",
        "outputId": "39e04aad-a5bd-4cb8-8ca3-7aa0ab5fef3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "class CNNSpectrumSensor:\n",
        "    def __init__(self, num_secondary_users=4):\n",
        "        self.num_sus = num_secondary_users\n",
        "        self.sensing_time = 0.001  # 1ms sensing interval\n",
        "        self.total_time = 60      # 1 minute simulation\n",
        "        self.num_iterations = int(self.total_time / self.sensing_time)\n",
        "        self.window_size = 128    # Input window size for CNN\n",
        "        self.model = None\n",
        "\n",
        "    def build_cnn_model(self):\n",
        "        \"\"\"Build CNN model for spectrum sensing\"\"\"\n",
        "        model = models.Sequential([\n",
        "            # Input layer\n",
        "            layers.Input(shape=(self.window_size, 6)),  # [I, Q, SNR, path_loss, fading, position]\n",
        "\n",
        "            # Convolutional layers\n",
        "            layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling1D(2),\n",
        "\n",
        "            layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling1D(2),\n",
        "\n",
        "            layers.Conv1D(256, 3, activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling1D(2),\n",
        "\n",
        "            # Dense layers\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(256, activation='relu'),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"Prepare data for CNN\"\"\"\n",
        "        # Create feature matrix\n",
        "        X = np.zeros((len(df), self.window_size, 6))\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            # Generate I/Q samples based on SNR and channel conditions\n",
        "            t = np.linspace(0, self.sensing_time, self.window_size)\n",
        "            snr = df.iloc[i]['snr']\n",
        "            path_loss = df.iloc[i]['path_loss']\n",
        "            fading = df.iloc[i]['fading_magnitude']\n",
        "\n",
        "            # Generate complex signal\n",
        "            signal = np.exp(1j * 2 * np.pi * 1000 * t)  # 1 kHz signal\n",
        "            signal = signal * np.sqrt(10**(snr/10))\n",
        "\n",
        "            # Add channel effects\n",
        "            signal = signal * fading * 10**(-path_loss/20)\n",
        "\n",
        "            # Add noise\n",
        "            noise = np.random.normal(0, 1, self.window_size) + 1j * np.random.normal(0, 1, self.window_size)\n",
        "            noisy_signal = signal + noise\n",
        "\n",
        "            # Fill feature matrix\n",
        "            X[i, :, 0] = noisy_signal.real  # I component\n",
        "            X[i, :, 1] = noisy_signal.imag  # Q component\n",
        "            X[i, :, 2] = snr * np.ones(self.window_size)  # SNR\n",
        "            X[i, :, 3] = path_loss * np.ones(self.window_size)  # Path loss\n",
        "            X[i, :, 4] = fading * np.ones(self.window_size)  # Fading\n",
        "            X[i, :, 5] = np.sqrt(df.iloc[i]['x']**2 + df.iloc[i]['y']**2 + df.iloc[i]['z']**2)  # Distance\n",
        "\n",
        "        # Normalize features\n",
        "        for i in range(X.shape[2]):\n",
        "            scaler = StandardScaler()\n",
        "            X[:, :, i] = scaler.fit_transform(X[:, :, i])\n",
        "\n",
        "        y = df['primary_user_present'].values\n",
        "        return X, y\n",
        "\n",
        "def run_simulation():\n",
        "    try:\n",
        "        # Load dataset\n",
        "        print(\"Loading dataset...\")\n",
        "        df = pd.read_hdf('cr_uav_dataset_10k.h5', key='data')\n",
        "\n",
        "        # Initialize simulation parameters\n",
        "        cnn_sensor = CNNSpectrumSensor(num_secondary_users=4)\n",
        "\n",
        "        # Create SNR bins with wider ranges to ensure sufficient samples\n",
        "        snr_bins = np.arange(-20, 6, 2)  # Changed step size to 2\n",
        "        results = []\n",
        "\n",
        "        # Print dataset statistics\n",
        "        print(f\"Total samples in dataset: {len(df)}\")\n",
        "        print(f\"SNR range in dataset: [{df['snr'].min():.1f}, {df['snr'].max():.1f}]\")\n",
        "\n",
        "        # Run simulation for each SNR bin\n",
        "        for snr_min, snr_max in zip(snr_bins[:-1], snr_bins[1:]):\n",
        "            try:\n",
        "                # Filter dataset for current SNR range\n",
        "                df_snr = df[(df['snr'] >= snr_min) & (df['snr'] < snr_max)]\n",
        "\n",
        "                print(f\"Processing SNR range [{snr_min}, {snr_max}] dB with {len(df_snr)} samples\")\n",
        "\n",
        "                if len(df_snr) < 100:  # Reduced minimum sample requirement\n",
        "                    print(f\"Insufficient samples for SNR range [{snr_min}, {snr_max}] dB\")\n",
        "                    continue\n",
        "\n",
        "                # Prepare data\n",
        "                X, y = cnn_sensor.prepare_data(df_snr)\n",
        "\n",
        "                # Split data\n",
        "                split_idx = int(0.8 * len(X))\n",
        "                X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "                y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "                # Build and train model\n",
        "                cnn_sensor.model = cnn_sensor.build_cnn_model()\n",
        "\n",
        "                # Train model\n",
        "                history = cnn_sensor.model.fit(\n",
        "                    X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "                # Evaluate performance\n",
        "                y_pred = cnn_sensor.model.predict(X_test, verbose=0)\n",
        "                fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "\n",
        "                # Calculate cooperative detection (OR-rule for multiple SUs)\n",
        "                coop_detection = 1 - np.prod([1-tpr[1] for _ in range(cnn_sensor.num_sus)])\n",
        "\n",
        "                # Store results using average SNR of the bin\n",
        "                avg_snr = (snr_min + snr_max) / 2\n",
        "                results.append({\n",
        "                    'snr': avg_snr,\n",
        "                    'snr_min': snr_min,\n",
        "                    'snr_max': snr_max,\n",
        "                    'num_samples': len(df_snr),\n",
        "                    'detection_prob': coop_detection,\n",
        "                    'false_alarm_prob': fpr[1],\n",
        "                    'training_accuracy': history.history['accuracy'][-1],\n",
        "                    'validation_accuracy': history.history['val_accuracy'][-1]\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing SNR range [{snr_min}, {snr_max}] dB: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if not results:\n",
        "            raise ValueError(\"No valid results generated from any SNR range\")\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Sort results by SNR\n",
        "        results_df = results_df.sort_values('snr')\n",
        "\n",
        "        # Create plots\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.errorbar(results_df['snr'], results_df['detection_prob'],\n",
        "                    xerr=(results_df['snr_max'] - results_df['snr_min'])/2,\n",
        "                    fmt='o-', label='Cooperative Detection',\n",
        "                    linewidth=2, markersize=8, capsize=5)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.xlabel('SNR (dB)', fontsize=12)\n",
        "        plt.ylabel('Probability of Detection', fontsize=12)\n",
        "        plt.title(f'CNN-based Detection Performance vs SNR\\n({cnn_sensor.num_sus} Secondary Users)',\n",
        "                  fontsize=14, pad=20)\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.xlim(min(results_df['snr'])-2, max(results_df['snr'])+2)\n",
        "        plt.ylim(0, 1.1)\n",
        "        plt.grid(True)\n",
        "        plt.savefig('cnn_simulation_results.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Plot training metrics\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Training/Validation Accuracy\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(results_df['snr'], results_df['training_accuracy'], 'o-',\n",
        "                label='Training', linewidth=2, markersize=6)\n",
        "        plt.plot(results_df['snr'], results_df['validation_accuracy'], 's-',\n",
        "                label='Validation', linewidth=2, markersize=6)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.xlabel('SNR (dB)', fontsize=12)\n",
        "        plt.ylabel('Accuracy', fontsize=12)\n",
        "        plt.title('Model Accuracy vs SNR', fontsize=14)\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.ylim(0, 1.1)\n",
        "\n",
        "        # Sample Distribution\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.bar(results_df['snr'], results_df['num_samples'])\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.xlabel('SNR (dB)', fontsize=12)\n",
        "        plt.ylabel('Number of Samples', fontsize=12)\n",
        "        plt.title('Sample Distribution', fontsize=14)\n",
        "\n",
        "        # ROC-like plot\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(results_df['false_alarm_prob'], results_df['detection_prob'], 'o-',\n",
        "                linewidth=2, markersize=6, color='green')\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.xlabel('Probability of False Alarm', fontsize=12)\n",
        "        plt.ylabel('Probability of Detection', fontsize=12)\n",
        "        plt.title('Detection vs False Alarm', fontsize=14)\n",
        "        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "        plt.axis('square')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('cnn_training_metrics.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Print performance summary\n",
        "        print(\"\\nCNN Simulation Results Summary\")\n",
        "        print(\"-----------------------------\")\n",
        "        print(f\"Number of Secondary Users: {cnn_sensor.num_sus}\")\n",
        "        print(f\"Total Simulation Time: {cnn_sensor.total_time} seconds\")\n",
        "        print(f\"Sensing Interval: {cnn_sensor.sensing_time} seconds\")\n",
        "        print(\"\\nPerformance Metrics:\")\n",
        "        print(results_df.round(4))\n",
        "\n",
        "        # Save results\n",
        "        results_df.to_csv('cnn_simulation_results.csv', index=False)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Simulation failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # Run simulation\n",
        "    results_df = run_simulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZfAVft8FaS1",
        "outputId": "9473e1fa-60f7-4ec6-906d-423defeb282e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Total samples in dataset: 10000\n",
            "SNR range in dataset: [-20.0, 5.0]\n",
            "Processing SNR range [-20, -18] dB with 801 samples\n",
            "Processing SNR range [-18, -16] dB with 808 samples\n",
            "Processing SNR range [-16, -14] dB with 745 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c09b32bdb40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing SNR range [-14, -12] dB with 844 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c09b29f9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing SNR range [-12, -10] dB with 800 samples\n",
            "Processing SNR range [-10, -8] dB with 835 samples\n",
            "Processing SNR range [-8, -6] dB with 779 samples\n",
            "Processing SNR range [-6, -4] dB with 787 samples\n",
            "Processing SNR range [-4, -2] dB with 750 samples\n",
            "Processing SNR range [-2, 0] dB with 813 samples\n",
            "Processing SNR range [0, 2] dB with 817 samples\n",
            "Processing SNR range [2, 4] dB with 832 samples\n",
            "\n",
            "CNN Simulation Results Summary\n",
            "-----------------------------\n",
            "Number of Secondary Users: 4\n",
            "Total Simulation Time: 60 seconds\n",
            "Sensing Interval: 0.001 seconds\n",
            "\n",
            "Performance Metrics:\n",
            "     snr  snr_min  snr_max  num_samples  detection_prob  false_alarm_prob  \\\n",
            "0  -19.0      -20      -18          801          0.0000            0.0133   \n",
            "1  -17.0      -18      -16          808          0.0000            0.0122   \n",
            "2  -15.0      -16      -14          745          0.0503            0.0000   \n",
            "3  -13.0      -14      -12          844          0.0523            0.0000   \n",
            "4  -11.0      -12      -10          800          0.0468            0.0000   \n",
            "5   -9.0      -10       -8          835          0.0000            0.0115   \n",
            "6   -7.0       -8       -6          779          0.0523            0.0000   \n",
            "7   -5.0       -6       -4          787          0.0452            0.0000   \n",
            "8   -3.0       -4       -2          750          0.0000            0.0139   \n",
            "9   -1.0       -2        0          813          0.0485            0.0000   \n",
            "10   1.0        0        2          817          0.0452            0.0000   \n",
            "11   3.0        2        4          832          0.0479            0.0000   \n",
            "\n",
            "    training_accuracy  validation_accuracy  \n",
            "0              0.8906               0.4688  \n",
            "1              0.9322               0.5692  \n",
            "2              0.9538               0.5667  \n",
            "3              0.9222               0.4593  \n",
            "4              0.9023               0.4375  \n",
            "5              0.9363               0.5299  \n",
            "6              0.9096               0.5680  \n",
            "7              0.9006               0.4683  \n",
            "8              0.9250               0.4750  \n",
            "9              0.8731               0.4923  \n",
            "10             0.9291               0.5115  \n",
            "11             0.8966               0.5188  \n"
          ]
        }
      ]
    }
  ]
}